{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01887478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bbdfa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"Qwen/Qwen1.5-1.8B-Chat\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "546f2e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efd1606768c484397f108591ef62e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6be429479b475f8270f82bf974290a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eabe449f2d74c2597f8d1104425c9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cbfda8510f44509c312495d95f676d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdac2c9fcb6d467180a438fa4249de4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a4aafec8db4cec9f4d167d46979af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15df1ea4223049adb017309a77e5f7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, trust_remote_code=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ee8c5d",
   "metadata": {},
   "source": [
    "The idea is to run some inference for:\n",
    "\n",
    "(1) a single input\n",
    "(2) a batched input\n",
    "\n",
    "For each case, try setting `num_return_sequences` as 1 and as > 1.\n",
    "\n",
    "Explore the model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9a548e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_single = \"What is the capital of France?\"\n",
    "\n",
    "input_batch = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"What is the largest mammal?\",\n",
    "    \"Who wrote 'To Kill a Mockingbird'?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c776961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abe33692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single input, num_return_sequences=1\n",
    "\n",
    "# General pipeline is tokenize -> generate -> decode -> parse\n",
    "tokens_single = tokenizer(input_single, return_tensors=\"pt\", return_attention_mask=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b80b59ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "565032ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[3838,  374,  279, 6722,  315, 9625,   30]], device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]], device='mps:0')}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74350d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishanth/opt/anaconda3/envs/lm-mastery-lab/lib/python3.10/site-packages/transformers/pytorch_utils.py:335: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 3838,   374,   279,  6722,   315,  9625,    30, 12095,    13,  1084,\n",
       "           374,   264, 12752,    11, 31592,    11,   323,  4948,  4126,   304,\n",
       "          9625,    11,  3881,   369,  1181, 26277, 59924,  1741,   438,   279,\n",
       "           468,  3092,   301, 21938,    11, 43464,  9420,   373, 56729,    11,\n",
       "           323,   279,  9729, 48506, 16328,    13, 12095,  1083,   702,   264,\n",
       "         52314, 18560,  6109,    11,   448,  1657, 42554]], device='mps:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_tokens_single = model.generate(\n",
    "    **tokens_single,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "op_tokens_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf9126ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the capital of France? Paris. It is a cultural, artistic, and political center in France, known for its iconic landmarks such as the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. Paris also has a thriving arts scene, with many galleries']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_single = tokenizer.batch_decode(op_tokens_single, skip_special_tokens=True)\n",
    "op_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef74009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris. It is a cultural, artistic, and political center in France, known for its iconic landmarks such as the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. Paris also has a thriving arts scene, with many galleries\n"
     ]
    }
   ],
   "source": [
    "print(op_single[0][len(input_single):].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "746b21d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  3838,    374,    279,   6722,    315,   9625,     30,  12095, 151643,\n",
       "         111632,   3837,  35946, 112914, 105012,   1773,    220,   1304,   3979,\n",
       "            563,  13970,     11,    358,    614,   9498,    311,  15401,    382,\n",
       "             16,     13,   3085,    271,     17,     13,   1634,    271,     18,\n",
       "             13,   1752,    271,     19,     13,   1913,    271,     20,     13,\n",
       "           3216,  51461,    117,  16038,  31838,  89012,   9370, 109949,    330,\n",
       "         111632,   3837,  35946],\n",
       "        [  3838,    374,    279,   6722,    315,   9625,     30,  12095, 151643,\n",
       "         116379, 100405,  99486, 104053,   3837,  77288, 116379, 102181,  34187,\n",
       "          99744,  99623, 104330, 104053,   1773,  99424, 101047,  97639, 101942,\n",
       "         101199,  46944, 106888,  99279,  29490,   5122, 100078,  34204,  99257,\n",
       "           5373, 114791,   5373, 101064, 103816,  29826,   3837, 104019, 104987,\n",
       "          99657,   5373,  99614,  33108, 104271,   3837,  91572, 107919, 104045,\n",
       "         100701, 101913,  19108],\n",
       "        [  3838,    374,    279,   6722,    315,   9625,     30,  12095,     13,\n",
       "         151643, 107064, 104429,  24339,  20412, 100022, 100134, 101945,  39907,\n",
       "           3837,  99569, 101181,  18493, 104328, 103993, 107064, 104429,   3837,\n",
       "          42411, 101140, 104682,  34187, 104654, 100825,  99921,   3837, 105012,\n",
       "          34187,  26940, 100750, 102227,  99686, 105733,  25067,  33108,  26940,\n",
       "         104629, 107697,  65101,  87243, 101889,  85336, 101224, 106004, 100189,\n",
       "          99740,  93823,   9370],\n",
       "        [  3838,    374,    279,   6722,    315,   9625,     30,  12095,     13,\n",
       "            715, 106004,  20412, 104328,   9370, 106114, 101037,  11319,   4710,\n",
       "          20412,   9370,   3837, 106004,  20412, 104328,   9370, 106114,   1773,\n",
       "         114566, 109648, 104136,  48443, 106004,   9909,  59604,   7552, 103987,\n",
       "         104328, 106758,   3837, 101202,  99458,  99469, 114833,   3837,  20412,\n",
       "          75882,  28404,   9370,  99346,   5373, 108444, 101091,  99488,   1773,\n",
       "          99652, 103926,  99164],\n",
       "        [  3838,    374,    279,   6722,    315,   9625,     30,  12095,     13,\n",
       "            671,  59604,    671,  49000, 151643, 107267, 100682,   3837,  99607,\n",
       "         104174,  99490,    271, 106004,  20412, 104328,   9370, 106114,  33108,\n",
       "         100082,  99490,   3837, 103987, 101202,  99458,  99469,  64817, 100490,\n",
       "           3837,  67364,  99635, 104114,   5373,  60686, 103810,  82847, 108738,\n",
       "         112264,   3837,  58463,  97120, 117564,   1773, 111437,  99489, 105891,\n",
       "          99348,   5373, 100377]], device='mps:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single input, num_return_sequences > 1\n",
    "op_tokens_single_seq = model.generate(\n",
    "    **tokens_single,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=5,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "op_tokens_single_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e92ea285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the capital of France? Paris慢慢地，我学会了欣赏。  ____________ slowly, I have learned to appreciate.\\n\\n1. With\\n\\n2. As\\n\\n3. For\\n\\n4. On\\n\\n5. By 根据所给的句子 \"慢慢地，我',\n",
       " 'What is the capital of France? Paris活得简单就是快乐，但活得复杂了也不一定会有快乐。生活中的我们经常处于一个复杂的境地：忙于工作、家务、家庭琐事，还要照顾孩子、朋友和家人，同时又要追求事业上的成功',\n",
       " 'What is the capital of France? Paris.实地考察法是历史学习的重要方法，某同学在法国进行了实地考察，他首先参观了卢浮宫，欣赏了《蒙娜丽莎》和《胜利女神像》，然后去感受巴黎圣母院的',\n",
       " 'What is the capital of France? Paris. \\n巴黎是法国的首都吗？ \\n\\n是的，巴黎是法国的首都。以下是详细的解释：\\n\\n巴黎（Paris）位于法国北部，塞纳河畔，是该国的经济、文化和政治中心。它拥有着',\n",
       " 'What is the capital of France? Paris. #Paris #France不断地变化，不断发展的城市\\n\\n巴黎是法国的首都和最大城市，位于塞纳河右岸，东临德国、西濒英吉利海峡，南界地中海。这里是世界著名的文化、艺术']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_single_seq = tokenizer.batch_decode(op_tokens_single_seq, skip_special_tokens=True)\n",
    "op_single_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4f15ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Paris慢慢地，我学会了欣赏。  ____________ slowly, I have learned to appreciate.\\n\\n1. With\\n\\n2. As\\n\\n3. For\\n\\n4. On\\n\\n5. By 根据所给的句子 \"慢慢地，我',\n",
       " 'Paris活得简单就是快乐，但活得复杂了也不一定会有快乐。生活中的我们经常处于一个复杂的境地：忙于工作、家务、家庭琐事，还要照顾孩子、朋友和家人，同时又要追求事业上的成功',\n",
       " 'Paris.实地考察法是历史学习的重要方法，某同学在法国进行了实地考察，他首先参观了卢浮宫，欣赏了《蒙娜丽莎》和《胜利女神像》，然后去感受巴黎圣母院的',\n",
       " 'Paris. \\n巴黎是法国的首都吗？ \\n\\n是的，巴黎是法国的首都。以下是详细的解释：\\n\\n巴黎（Paris）位于法国北部，塞纳河畔，是该国的经济、文化和政治中心。它拥有着',\n",
       " 'Paris. #Paris #France不断地变化，不断发展的城市\\n\\n巴黎是法国的首都和最大城市，位于塞纳河右岸，东临德国、西濒英吉利海峡，南界地中海。这里是世界著名的文化、艺术']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[len(input_single):].strip() for x in op_single_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f5f5f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151643, 151643, 151643,   3838,    374,    279,   6722,    315,   9625,\n",
       "             30],\n",
       "        [151643, 151643, 151643,   3838,    374,    279,   7772,  34941,    278,\n",
       "             30],\n",
       "        [ 15191,   6139,    364,   1249,  26835,    264,  14563,    287,  22592,\n",
       "          69990]], device='mps:0'), 'attention_mask': tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch input, num_return_sequences=1\n",
    "tokens_batch = tokenizer(input_batch, return_tensors=\"pt\", return_attention_mask=True, padding=True).to(device)\n",
    "tokens_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd8490f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151643, 151643, 151643,   3838,    374,    279,   6722,    315,   9625,\n",
       "             30,  12095,     13,  12095,    374,    264,   3283,   7407,    304,\n",
       "          18172,   9625,    323,    374,   3881,    369,   1181,   9080,   3840,\n",
       "             11,  26277,  59924,     11,    323,  32976,   7674,     13,    576,\n",
       "           3283,    702,   1012,    279,   6722,    315,   9625,   2474,    279,\n",
       "          12592,  48993,    323,    572,  18562,   9555,    438,   1741,    389,\n",
       "           5768,    220,     17,     16,     11,    220],\n",
       "        [151643, 151643, 151643,   3838,    374,    279,   7772,  34941,    278,\n",
       "             30,    576,   7772,  34941,    278,    304,    279,   1879,    553,\n",
       "           8123,    374,    279,   6303,  50019,    320,     33,   6053,    268,\n",
       "           2912,   2416,   3091,  41349,    701,    892,    646,   3063,    705,\n",
       "            311,    220,     18,     15,  20044,   1293,    323,  17529,    916,\n",
       "            220,     17,     15,     15,  19608,     13,   8697,  56774,    525,\n",
       "           1730,    304,    678,    315,   9237,    594],\n",
       "        [ 15191,   6139,    364,   1249,  26835,    264,  14563,    287,  22592,\n",
       "          69990,  32007,  12066,     13, 151643, 113678,  53481,  34187, 100625,\n",
       "         107280, 104304, 109174, 112187, 111427,  33108, 115713, 105669,   1773,\n",
       "          99517,  23031, 101177,  99882,     41,    336,   9370, 102760, 112370,\n",
       "         101064, 116273,   3837, 110593, 107469, 104417, 102649,  17447,  99424,\n",
       "         104413,   1773,     41,    336, 101909, 105414,   5373, 107480,   5373,\n",
       "         107749, 104545,   3837, 100648, 102037,  99519]], device='mps:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_tokens_batch = model.generate(\n",
    "    **tokens_batch,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "op_tokens_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1db50280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the capital of France? Paris. Paris is a city located in northern France and is known for its rich history, iconic landmarks, and vibrant culture. The city has been the capital of France since the Middle Ages and was officially established as such on July 21, ',\n",
       " \"What is the largest mammal? The largest mammal in the world by volume is the blue whale (Balaenoptera musculus), which can grow up to 30 meters long and weigh over 200 tons. Blue whales are found in all of Earth's\",\n",
       " \"Who wrote 'To Kill a Mockingbird'? Harper Lee.很好地描述了美国南北战争时期的种族歧视和不公平待遇。她以一名叫Jem的男孩和他的家庭为主线，讲述了他们在南方小镇上生活的故事。Jem是一个聪明、勇敢、善良的孩子，他的父亲因为\"]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_batch = tokenizer.batch_decode(op_tokens_batch, skip_special_tokens=True)\n",
    "op_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d22737b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Paris. Paris is a city located in northern France and is known for its rich history, iconic landmarks, and vibrant culture. The city has been the capital of France since the Middle Ages and was officially established as such on July 21,',\n",
       " \"The largest mammal in the world by volume is the blue whale (Balaenoptera musculus), which can grow up to 30 meters long and weigh over 200 tons. Blue whales are found in all of Earth's\",\n",
       " 'Harper Lee.很好地描述了美国南北战争时期的种族歧视和不公平待遇。她以一名叫Jem的男孩和他的家庭为主线，讲述了他们在南方小镇上生活的故事。Jem是一个聪明、勇敢、善良的孩子，他的父亲因为']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[len(input_batch[i]):].strip() for i, x in enumerate(op_batch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89a4b068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishanth/opt/anaconda3/envs/lm-mastery-lab/lib/python3.10/site-packages/transformers/pytorch_utils.py:335: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[151643, 151643, 151643,   3838,    374,    279,   6722,    315,   9625,\n",
       "             30,  12095,     13,  12095,    374,    264,   6233,   3283,    304,\n",
       "           9625,     11,   3881,    369,   1181,  26277,  59924,   1741,    438,\n",
       "            279,    468,   3092,    301,  21938,     11,  43464,   9420,    373,\n",
       "          56729,     11,    323,    279,   9729,  48506,  16328,     13,   1084,\n",
       "            374,   1083,   2114,    311,   1657,  34409,  32000,    323,  32976,\n",
       "          12752,  16065,     11,   3259,    432,    264],\n",
       "        [151643, 151643, 151643,   3838,    374,    279,   6722,    315,   9625,\n",
       "             30,  12095,     13, 151643,   7681,  23967,    429,    330,  59604,\n",
       "              1,    374,    264,   3283,    323,    537,    264,   3146,     11,\n",
       "            773,    279,   4226,    374,    330,  59604,   3263,  12095,    374,\n",
       "            279,   6722,   3283,    315,   9625,     11,    892,    374,    264,\n",
       "           3146,   7407,    304,  10867,   4505,     13,   1084,    374,   3881,\n",
       "            369,   1181,   9080,   3840,     11,  26277],\n",
       "        [151643, 151643, 151643,   3838,    374,    279,   6722,    315,   9625,\n",
       "             30,  12095,     13,   2160,   1052,    264,   1992,    304,   9625,\n",
       "           1380,    498,    646,   3960,    803,    911,    279,   8585,   4128,\n",
       "            323,   7674,     30,   7414,     11,   1052,    525,   1657,   7482,\n",
       "            304,   9625,   1380,    498,    646,   3960,    803,    911,    279,\n",
       "           8585,   4128,    323,   7674,     13,   5692,    525,   1045,   5411,\n",
       "           2606,   1447,     16,     13,   8585,  11434],\n",
       "        [151643, 151643, 151643,   3838,    374,    279,   6722,    315,   9625,\n",
       "             30,  12095,     13,   6722,    315,   9625,  12095,     13,   6722,\n",
       "            315,   9625,  12095,     13,   6722,    315,   9625,  12095,     13,\n",
       "           6722,    315,   9625,  12095,     13,   6722,    315,   9625,  12095,\n",
       "             13,   6722,    315,   9625,  12095,     13,   6722,    315,   9625,\n",
       "          12095,     13,   6722,    315,   9625,  12095,     13,   6722,    315,\n",
       "           9625,  12095,     13,   6722,    315,   9625],\n",
       "        [151643, 151643, 151643,   3838,    374,    279,   6722,    315,   9625,\n",
       "             30,  12095,     11,   9625,     13, 151645, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643],\n",
       "        [151643, 151643, 151643,   3838,    374,    279,   7772,  34941,    278,\n",
       "             30,    576,   7772,  34941,    278,    304,    279,   1879,    374,\n",
       "            279,   6303,  50019,     11,    892,    646,   3063,    705,    311,\n",
       "            220,     16,     15,     15,   7541,    320,     18,     15,  20044,\n",
       "              8,   1293,    323,  17529,    916,    220,     17,     15,     15,\n",
       "          19608,    320,     16,     19,     15,  18266,  50921,    568,   8697,\n",
       "          56774,    525,   1730,    304,    678,  53180],\n",
       "        [151643, 151643, 151643,   3838,    374,    279,   7772,  34941,    278,\n",
       "             30,    576,   7772,  34941,    278,    389,   9237,    374,    279,\n",
       "           6303,  50019,     13,  22133,   6303,  56774,    646,  17529,    916,\n",
       "            220,     17,     15,     15,  19608,    323,   5545,  28316,    315,\n",
       "            705,    311,    220,     16,     15,     15,  20044,    320,     18,\n",
       "             18,     15,   7541,      8,    304,   3084,     11,   3259,   1105,\n",
       "           1045,    315,    279,   1429,  10951,   9898],\n",
       "        [151643, 151643, 151643,   3838,    374,    279,   7772,  34941,    278,\n",
       "             30,    576,   7772,  34941,    278,    389,   9237,    374,    279,\n",
       "           6303,  50019,     11,    892,    646,   3063,    705,    311,    220,\n",
       "             16,     15,     15,   7541,    320,     18,     15,  20044,      8,\n",
       "            304,   3084,    323,  17529,    705,    311,    220,     17,     15,\n",
       "             15,  19608,    320,     16,     23,     15,  18266,  19608,    568,\n",
       "           8697,  56774,    525,   1730,    304,    678],\n",
       "        [151643, 151643, 151643,   3838,    374,    279,   7772,  34941,    278,\n",
       "             30,    576,   7772,  34941,    278,    304,    279,   1879,    374,\n",
       "            279,   6303,  50019,     11,    892,    646,   3063,    705,    311,\n",
       "            220,     16,     15,     15,   7541,    320,     18,     15,  20044,\n",
       "              8,   1293,    323,  17529,    438,   1753,    438,    220,     17,\n",
       "             15,     15,  19608,    320,     16,     19,     20,  18266,  50921,\n",
       "            568,   1084,    702,    264,  34847,    293],\n",
       "        [151643, 151643, 151643,   3838,    374,    279,   7772,  34941,    278,\n",
       "             30,    576,   7772,  34941,    278,    304,    279,   1879,    374,\n",
       "            279,   6303,  50019,     11,    892,    646,   3063,    705,    311,\n",
       "            220,     16,     15,     15,   7541,    320,     18,     15,  20044,\n",
       "              8,   1293,    323,  17529,    705,    311,    220,     17,     15,\n",
       "             15,  19608,    320,     16,     19,     15,  18266,  19608,    568,\n",
       "           1084,    702,    264,  17545,  31654,   6787],\n",
       "        [ 15191,   6139,    364,   1249,  26835,    264,  14563,    287,  22592,\n",
       "          69990,  32007,  12066,     13, 151643,     13,    659,    659,    279,\n",
       "            659,    659,    659,    659,    659,  16448,   1986,   2150,  16555,\n",
       "            279,   8794,    315,    279,  11358,   1034,    330,  26490,    712,\n",
       "          12066,    594,   2014,  26835,    264,  14563,    287,  22592,      1,\n",
       "            553,  32007,  12066,     11,   4652,    304,    220,     16,     24,\n",
       "             21,     15,    624,    785,  11358,   1034],\n",
       "        [ 15191,   6139,    364,   1249,  26835,    264,  14563,    287,  22592,\n",
       "          69990,  32007,  12066,     13, 151643,  13065,    813,   3364,    315,\n",
       "          25962,    304,    279,   3693,   4882,     11,   2014,  26835,    264,\n",
       "          14563,    287,  22592,    374,    264,  11514,    553,  32007,  12066,\n",
       "            429,  10742,    279,   3364,    315,  47535,  95233,     11,    264,\n",
       "           3908,   3743,   7826,    705,   2337,    279,   8513,  45804,    323,\n",
       "            279,  16398,   5004,  11385,    304,    279],\n",
       "        [ 15191,   6139,    364,   1249,  26835,    264,  14563,    287,  22592,\n",
       "          69990,  32007,  12066,    198,  26490,    712,  12066,     11,    279,\n",
       "           3150,    315,    330,   1249,  26835,    264,  14563,    287,  22592,\n",
       "           1335,    572,   9223,    304,  20623,    323,  13938,    705,    304,\n",
       "            264,   2613,   6290,    448,   1059,   6562,     11,    619,    336,\n",
       "          95233,    323,  47769,   2408,  95233,     13,   2932,  18178,   2906,\n",
       "            304,   3128,    299,   5120,   4517,    323],\n",
       "        [ 15191,   6139,    364,   1249,  26835,    264,  14563,    287,  22592,\n",
       "          69990,  32007,  12066, 151643, 107267, 105009,  62926, 104107,    198,\n",
       "           2073,  26940, 109256, 102292,  52183,  33126, 100462,  25067,    854,\n",
       "          20412, 100625, 105022,  98671, 118840,  13935, 100339,  99774,  32948,\n",
       "         102280, 104032,   3837,  99558, 110593, 107280, 104304, 100728, 104417,\n",
       "         102649,  99727,  28072,  99603, 104111, 100714, 101064,   8545,  99295,\n",
       "          77598,  65278, 101949, 104103,   1773, 102332],\n",
       "        [ 15191,   6139,    364,   1249,  26835,    264,  14563,    287,  22592,\n",
       "          69990,  32007,  12066, 151643,   4103,  72743,   3359,    389,  19807,\n",
       "           2747,    198,     32,   1874,    315,  38170,  19571,  11626,    264,\n",
       "            422,   5404,     50,   3359,    389,    264,  19807,   2747,    419,\n",
       "           2003,     11,   9380,    432,  34987,    311,   3847,    369,   3807,\n",
       "           4115,     13,    576,  40965,  17112,    279,   2747,    518,    279,\n",
       "           5411,  41992,   5339,     11,    892,    572]], device='mps:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch input, num_return_sequences > 1\n",
    "op_tokens_batch_seq = model.generate(\n",
    "    **tokens_batch,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=5,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "op_tokens_batch_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e702946d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 60])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_tokens_batch_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9be763d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the capital of France? Paris. Paris is a beautiful city in France, known for its iconic landmarks such as the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. It is also home to many charming neighborhoods and vibrant cultural scenes, making it a',\n",
       " 'What is the capital of France? Paris. deduced that \"Paris\" is a city and not a country, so the answer is \"Paris\". Paris is the capital city of France, which is a country located in Western Europe. It is known for its rich history, iconic',\n",
       " 'What is the capital of France? Paris. Is there a place in France where you can learn more about the French language and culture? Yes, there are many places in France where you can learn more about the French language and culture. Here are some popular options:\\n\\n1. French Language',\n",
       " 'What is the capital of France? Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France',\n",
       " 'What is the capital of France? Paris, France.',\n",
       " 'What is the largest mammal? The largest mammal in the world is the blue whale, which can grow up to 100 feet (30 meters) long and weigh over 200 tons (140 metric tonnes). Blue whales are found in all oceans',\n",
       " 'What is the largest mammal? The largest mammal on Earth is the blue whale. Adult blue whales can weigh over 200 tons and reach lengths of up to 100 meters (330 feet) in length, making them some of the most massive animals',\n",
       " 'What is the largest mammal? The largest mammal on Earth is the blue whale, which can grow up to 100 feet (30 meters) in length and weigh up to 200 tons (180 metric tons). Blue whales are found in all',\n",
       " 'What is the largest mammal? The largest mammal in the world is the blue whale, which can grow up to 100 feet (30 meters) long and weigh as much as 200 tons (145 metric tonnes). It has a distinctive b',\n",
       " 'What is the largest mammal? The largest mammal in the world is the blue whale, which can grow up to 100 feet (30 meters) long and weigh up to 200 tons (140 metric tons). It has a gray-blue skin',\n",
       " 'Who wrote \\'To Kill a Mockingbird\\'? Harper Lee.. . . the . . . . . .\\nThis page describes the contents of the PDF file \"Harper Lee\\'s To Kill a Mockingbird\" by Harper Lee, published in 1960.\\nThe PDF file',\n",
       " \"Who wrote 'To Kill a Mockingbird'? Harper Lee. untold story of racism in the American South, To Kill a Mockingbird is a novel by Harper Lee that tells the story of Scout Finch, a young girl growing up during the Great Depression and the Civil War era in the\",\n",
       " 'Who wrote \\'To Kill a Mockingbird\\'? Harper Lee\\nHarper Lee, the author of \"To Kill a Mockingbird,\" was born in Alabama and grew up in a small town with her parents, Jem Finch and Mammy Finch. She attended school in Monroeville and',\n",
       " \"Who wrote 'To Kill a Mockingbird'? Harper Lee不断地练习并思考\\n“《杀死一只知更鸟》”是美国作家哈珀·李的一部著名小说，主要讲述了南北战争时期南方小镇阿提卡的一个普通家庭——斯考特一家的生活。在这\",\n",
       " \"Who wrote 'To Kill a Mockingbird'? Harper LeeDDoS attack on WordPress site\\nA group of malicious actors launched a DDoS attack on a WordPress site this week, leaving it unavailable to users for several hours. The attackers targeted the site at the popular blogging platform, which was\"]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_batch_seq = tokenizer.batch_decode(op_tokens_batch_seq, skip_special_tokens=True)\n",
    "op_batch_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_seq_responses = []\n",
    "\n",
    "for i in range(len(input_batch)):\n",
    "    input_text = input_batch[i]\n",
    "    input_length = len(input_text)\n",
    "    \n",
    "    sequences_for_this_input = op_batch_seq[i*5:(i+1)*5]\n",
    "    \n",
    "    cleaned_sequences = [seq[input_length:].strip() for seq in sequences_for_this_input]\n",
    "    \n",
    "    batch_seq_responses.append(cleaned_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a0eb8fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Paris. Paris is a beautiful city in France, known for its iconic landmarks such as the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. It is also home to many charming neighborhoods and vibrant cultural scenes, making it a',\n",
       "  'Paris. deduced that \"Paris\" is a city and not a country, so the answer is \"Paris\". Paris is the capital city of France, which is a country located in Western Europe. It is known for its rich history, iconic',\n",
       "  'Paris. Is there a place in France where you can learn more about the French language and culture? Yes, there are many places in France where you can learn more about the French language and culture. Here are some popular options:\\n\\n1. French Language',\n",
       "  'Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France Paris. capital of France',\n",
       "  'Paris, France.'],\n",
       " ['The largest mammal in the world is the blue whale, which can grow up to 100 feet (30 meters) long and weigh over 200 tons (140 metric tonnes). Blue whales are found in all oceans',\n",
       "  'The largest mammal on Earth is the blue whale. Adult blue whales can weigh over 200 tons and reach lengths of up to 100 meters (330 feet) in length, making them some of the most massive animals',\n",
       "  'The largest mammal on Earth is the blue whale, which can grow up to 100 feet (30 meters) in length and weigh up to 200 tons (180 metric tons). Blue whales are found in all',\n",
       "  'The largest mammal in the world is the blue whale, which can grow up to 100 feet (30 meters) long and weigh as much as 200 tons (145 metric tonnes). It has a distinctive b',\n",
       "  'The largest mammal in the world is the blue whale, which can grow up to 100 feet (30 meters) long and weigh up to 200 tons (140 metric tons). It has a gray-blue skin'],\n",
       " ['Harper Lee.. . . the . . . . . .\\nThis page describes the contents of the PDF file \"Harper Lee\\'s To Kill a Mockingbird\" by Harper Lee, published in 1960.\\nThe PDF file',\n",
       "  'Harper Lee. untold story of racism in the American South, To Kill a Mockingbird is a novel by Harper Lee that tells the story of Scout Finch, a young girl growing up during the Great Depression and the Civil War era in the',\n",
       "  'Harper Lee\\nHarper Lee, the author of \"To Kill a Mockingbird,\" was born in Alabama and grew up in a small town with her parents, Jem Finch and Mammy Finch. She attended school in Monroeville and',\n",
       "  'Harper Lee不断地练习并思考\\n“《杀死一只知更鸟》”是美国作家哈珀·李的一部著名小说，主要讲述了南北战争时期南方小镇阿提卡的一个普通家庭——斯考特一家的生活。在这',\n",
       "  'Harper LeeDDoS attack on WordPress site\\nA group of malicious actors launched a DDoS attack on a WordPress site this week, leaving it unavailable to users for several hours. The attackers targeted the site at the popular blogging platform, which was']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_seq_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "46a4c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation with chat template\n",
    "\n",
    "def format_prompt(inputs: list) -> list[list[str]]:\n",
    "    formatted = []\n",
    "    for i in inputs:\n",
    "        formatted.append([\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are brief and concise in your answers. If an answer can be a single word, it should be.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": i\n",
    "            }\n",
    "        ])\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2e74c810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|im_start|>system\\nYou are brief and concise in your answers. If an answer can be a single word, it should be.<|im_end|>\\n<|im_start|>user\\nWhat is the capital of France?<|im_end|>\\n<|im_start|>assistant\\n',\n",
       " '<|im_start|>system\\nYou are brief and concise in your answers. If an answer can be a single word, it should be.<|im_end|>\\n<|im_start|>user\\nWhat is the largest mammal?<|im_end|>\\n<|im_start|>assistant\\n',\n",
       " \"<|im_start|>system\\nYou are brief and concise in your answers. If an answer can be a single word, it should be.<|im_end|>\\n<|im_start|>user\\nWho wrote 'To Kill a Mockingbird'?<|im_end|>\\n<|im_start|>assistant\\n\"]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch_chat = tokenizer.apply_chat_template(\n",
    "    format_prompt(input_batch),\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=False\n",
    ")\n",
    "input_batch_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ac07d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151643, 151643, 151643, 151644,   8948,    198,   2610,    525,   9814,\n",
       "            323,  63594,    304,    697,  11253,     13,   1416,    458,   4226,\n",
       "            646,    387,    264,   3175,   3409,     11,    432,   1265,    387,\n",
       "             13, 151645,    198, 151644,    872,    198,   3838,    374,    279,\n",
       "           6722,    315,   9625,     30, 151645,    198, 151644,  77091,    198],\n",
       "        [151643, 151643, 151643, 151644,   8948,    198,   2610,    525,   9814,\n",
       "            323,  63594,    304,    697,  11253,     13,   1416,    458,   4226,\n",
       "            646,    387,    264,   3175,   3409,     11,    432,   1265,    387,\n",
       "             13, 151645,    198, 151644,    872,    198,   3838,    374,    279,\n",
       "           7772,  34941,    278,     30, 151645,    198, 151644,  77091,    198],\n",
       "        [151644,   8948,    198,   2610,    525,   9814,    323,  63594,    304,\n",
       "            697,  11253,     13,   1416,    458,   4226,    646,    387,    264,\n",
       "           3175,   3409,     11,    432,   1265,    387,     13, 151645,    198,\n",
       "         151644,    872,    198,  15191,   6139,    364,   1249,  26835,    264,\n",
       "          14563,    287,  22592,  69990, 151645,    198, 151644,  77091,    198]],\n",
       "       device='mps:0'), 'attention_mask': tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='mps:0')}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_batch_chat = tokenizer(input_batch_chat, return_tensors=\"pt\", return_attention_mask=True, padding=True).to(device)\n",
    "tokens_batch_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5cf3afd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishanth/opt/anaconda3/envs/lm-mastery-lab/lib/python3.10/site-packages/transformers/pytorch_utils.py:335: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[151643, 151643, 151643, 151644,   8948,    198,   2610,    525,   9814,\n",
       "            323,  63594,    304,    697,  11253,     13,   1416,    458,   4226,\n",
       "            646,    387,    264,   3175,   3409,     11,    432,   1265,    387,\n",
       "             13, 151645,    198, 151644,    872,    198,   3838,    374,    279,\n",
       "           6722,    315,   9625,     30, 151645,    198, 151644,  77091,    198,\n",
       "          59604, 151645, 151643, 151643],\n",
       "        [151643, 151643, 151643, 151644,   8948,    198,   2610,    525,   9814,\n",
       "            323,  63594,    304,    697,  11253,     13,   1416,    458,   4226,\n",
       "            646,    387,    264,   3175,   3409,     11,    432,   1265,    387,\n",
       "             13, 151645,    198, 151644,    872,    198,   3838,    374,    279,\n",
       "           7772,  34941,    278,     30, 151645,    198, 151644,  77091,    198,\n",
       "           1639,   1574,     13, 151645],\n",
       "        [151644,   8948,    198,   2610,    525,   9814,    323,  63594,    304,\n",
       "            697,  11253,     13,   1416,    458,   4226,    646,    387,    264,\n",
       "           3175,   3409,     11,    432,   1265,    387,     13, 151645,    198,\n",
       "         151644,    872,    198,  15191,   6139,    364,   1249,  26835,    264,\n",
       "          14563,    287,  22592,  69990, 151645,    198, 151644,  77091,    198,\n",
       "          26490,    712,  12066, 151645]], device='mps:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_tokens_batch_chat = model.generate(\n",
    "    **tokens_batch_chat,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "op_tokens_batch_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "632f17d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system\\nYou are brief and concise in your answers. If an answer can be a single word, it should be.\\nuser\\nWhat is the capital of France?\\nassistant\\nParis',\n",
       " 'system\\nYou are brief and concise in your answers. If an answer can be a single word, it should be.\\nuser\\nWhat is the largest mammal?\\nassistant\\nWhale.',\n",
       " \"system\\nYou are brief and concise in your answers. If an answer can be a single word, it should be.\\nuser\\nWho wrote 'To Kill a Mockingbird'?\\nassistant\\nHarper Lee\"]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_batch_chat = tokenizer.batch_decode(op_tokens_batch_chat, skip_special_tokens=True)\n",
    "op_batch_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fc9c35e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris\n",
      "Whale.\n",
      "Harper Lee\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for i in op_batch_chat:\n",
    "    # Extract everything after the last assistant response\n",
    "    match = re.search(r'assistant\\n(.*)', i)\n",
    "    if match:\n",
    "        response = match.group(1).strip()\n",
    "        print(response)\n",
    "    else:\n",
    "        print(\"No response found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0aaad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
