{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f15ed0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import AutoModelForTokenClassification, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eaf1d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3de22b7b824cd8ad23eab197d80c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8978d41965df4e068ae061041092b53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/phi-3-mini-4k-instruct\",\n",
    "    device_map=\"mps\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b550a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c15f84dbdf4817892cbab6f5caa854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866d248c39f240b09e0325d5797bf85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9865d4710e4a0282da4dbe4daff819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0a8c76147f48a58cd2f9497ec00ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997292159736415388d3a3c24c3cdbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17c8b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Why did the chicken cross the morbius strip? <|assistant|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b886d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e606df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "969043c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3750,  1258,   278,   521, 21475,  4891,   278,  3036, 29890,  2482,\n",
       "         17820, 29973, 29871, 32001]], device='mps:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7836b118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "op = model.generate(\n",
    "    input_ids[\"input_ids\"],\n",
    "    max_new_tokens=25,\n",
    "    use_cache=False,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b8674bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9100137d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the chicken cross the morbius strip? <|assistant|> The chicken crossed the morbius strip to get to the other side, just like it would cross any other road or'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(op[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0becd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why\n",
      "did\n",
      "the\n",
      "ch\n",
      "icken\n",
      "cross\n",
      "the\n",
      "mor\n",
      "b\n",
      "ius\n",
      "strip\n",
      "?\n",
      "\n",
      "<|assistant|>\n"
     ]
    }
   ],
   "source": [
    "for i in input_ids[\"input_ids\"][0]:\n",
    "    print(tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f15286a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7d02ddcb7945c1ad0e5e5ab102dcba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a50b4203ea4e4caccd4d31156a7a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28a271a600c42bdbffa622dead8dd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13cc522b19e4690be5195218f906fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7740de6d91d04016b70954ffa425af86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d47e7313c1849e7a1c6019c6d0bd245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd54358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6e4e6f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Trump was particularly peeved by Musk insinuating the president was tied to the late sex offender Jeffrey Epstein, claiming Trump was “in the Epstein files.”\"\"\"\n",
    "\n",
    "# https://www.politico.com/news/2025/06/08/musk-trump-ceasefire-call-00393527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2fb528a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ner_pipeline(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d43340f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "04965329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b5f0514c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': 'B-PER',\n",
       " 'score': 0.999616,\n",
       " 'index': 1,\n",
       " 'word': 'Trump',\n",
       " 'start': 0,\n",
       " 'end': 5}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "18d10ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5 B-PER\n",
      "33 35 B-PER\n",
      "35 37 B-PER\n",
      "98 105 B-PER\n",
      "106 107 I-PER\n",
      "107 109 I-PER\n",
      "109 113 I-PER\n",
      "124 129 B-PER\n",
      "142 143 B-PER\n",
      "143 145 B-PER\n",
      "145 149 B-PER\n"
     ]
    }
   ],
   "source": [
    "for i in results:\n",
    "    print(i[\"start\"], i[\"end\"], i[\"entity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "977bfe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dcd6f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(results):\n",
    "    beg = results[i][\"start\"]\n",
    "    term = results[i][\"end\"]\n",
    "    ent = results[i][\"entity\"]\n",
    "\n",
    "    if i + 1 >= len(results):\n",
    "        entity_dict[ent].append((beg, term))\n",
    "        break\n",
    "\n",
    "    while i + 1 < len(results) and term == results[i+1][\"start\"]:\n",
    "        term = results[i+1][\"end\"]\n",
    "        i += 1\n",
    "\n",
    "    # entity_dict[ent].append((beg, term))\n",
    "    entity_dict[(beg, term)] = ent\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "162821f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 5): 'B-PER',\n",
       " (33, 37): 'B-PER',\n",
       " (98, 105): 'B-PER',\n",
       " (106, 113): 'I-PER',\n",
       " (124, 129): 'B-PER',\n",
       " (142, 149): 'B-PER'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4a6bfd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "redac = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a121be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = 0\n",
    "max_end_ind = 0\n",
    "for key, value in entity_dict.items():\n",
    "    redac += text[end:key[0]] + f\"<{value}>\" + \" \"\n",
    "    end = key[1] + 1\n",
    "    max_end_ind = max(max_end_ind, end)\n",
    "redac += text[max_end_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9cda2f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump was particularly peeved by Musk insinuating the president was tied to the late sex offender Jeffrey Epstein, claiming Trump was “in the Epstein files.”\n",
      "<B-PER> was particularly peeved by <B-PER> insinuating the president was tied to the late sex offender <B-PER> <I-PER>  claiming <B-PER> was “in the <B-PER> files.”\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(redac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f884954d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-mastery-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
